#!/usr/bin/env python3
"""
Analyse dÃ©taillÃ©e des 19-20 juillet pour retrouver les -800â‚¬
"""

from datetime import date, datetime

import pandas as pd


def analyze_last_two_days(csv_path):
    """Analyse dÃ©taillÃ©e des 19-20 juillet"""
    print("ðŸ” RECHERCHE DES -800â‚¬ - 19-20 JUILLET")
    print("=" * 50)
    
    # Lecture du CSV
    df = pd.read_csv(csv_path, sep=';')
    df['Date(UTC)'] = pd.to_datetime(df['Date(UTC)'])
    df['Date'] = df['Date(UTC)'].dt.date
    
    # Filtre sur les 2 derniers jours
    target_dates = [date(2025, 7, 19), date(2025, 7, 20)]
    recent_trades = df[df['Date'].isin(target_dates)].copy()
    
    print(f"ðŸ“Š DONNÃ‰ES FILTRÃ‰ES")
    print(f"   Trades 19-20 juillet: {len(recent_trades):,}")
    
    # Calcul du flux EUR (rÃ©el)
    recent_trades['EUR_Flow'] = recent_trades.apply(lambda row: 
        row['Total'] + row['Fee'] if row['Type'] == 'SELL' 
        else -(row['Total'] + row['Fee']), axis=1)
    
    # Analyse par jour
    for target_date in target_dates:
        day_trades = recent_trades[recent_trades['Date'] == target_date].copy()
        
        if len(day_trades) == 0:
            continue
            
        print(f"\nðŸ“… {target_date.strftime('%d JUILLET %Y')}")
        print(f"   Transactions: {len(day_trades):,}")
        
        # Flux EUR total
        daily_flow = day_trades['EUR_Flow'].sum()
        print(f"   Flux EUR net: {daily_flow:+.2f}â‚¬")
        
        # Analyse par heure
        day_trades['Hour'] = day_trades['Date(UTC)'].dt.hour
        hourly_flows = day_trades.groupby('Hour')['EUR_Flow'].sum()
        
        print(f"   RÃ©partition horaire:")
        for hour, flow in hourly_flows.items():
            if abs(flow) > 100:  # Seulement les heures significatives
                status = "ðŸš¨" if flow < -500 else "ðŸ“‰" if flow < 0 else "ðŸ“ˆ"
                print(f"      {hour:02d}h: {flow:+8.2f}â‚¬ {status}")
        
        # Recherche des minutes catastrophiques
        print(f"   Minutes avec pertes >200â‚¬:")
        day_trades['Minute_Key'] = day_trades['Date(UTC)'].dt.strftime('%H:%M')
        minute_flows = day_trades.groupby('Minute_Key')['EUR_Flow'].sum()
        bad_minutes = minute_flows[minute_flows < -200].sort_values()
        
        for minute, flow in bad_minutes.items():
            print(f"      {minute}: {flow:+.2f}â‚¬")
            
            # DÃ©tail de cette minute
            minute_trades = day_trades[day_trades['Minute_Key'] == minute]
            pairs_in_minute = minute_trades.groupby('Pair')['EUR_Flow'].sum()
            for pair, pair_flow in pairs_in_minute.items():
                if abs(pair_flow) > 50:
                    print(f"         {pair}: {pair_flow:+.2f}â‚¬")
    
    # Calcul cumulatif sur les 2 jours
    print(f"\nðŸ“ˆ Ã‰VOLUTION CUMULATIVE (19-20 JUILLET)")
    recent_sorted = recent_trades.sort_values('Date(UTC)')
    recent_sorted['Cumulative_Flow'] = recent_sorted['EUR_Flow'].cumsum()
    
    # Points clÃ©s
    start_balance = 20000  # SupposÃ©
    min_point = recent_sorted['Cumulative_Flow'].min()
    max_point = recent_sorted['Cumulative_Flow'].max()
    final_point = recent_sorted['Cumulative_Flow'].iloc[-1]
    
    min_time = recent_sorted.loc[recent_sorted['Cumulative_Flow'].idxmin(), 'Date(UTC)']
    max_time = recent_sorted.loc[recent_sorted['Cumulative_Flow'].idxmax(), 'Date(UTC)']
    
    print(f"   Point le plus bas: {min_time} = {start_balance + min_point:,.2f}â‚¬ ({min_point:+.2f}â‚¬)")
    print(f"   Point le plus haut: {max_time} = {start_balance + max_point:,.2f}â‚¬ ({max_point:+.2f}â‚¬)")
    print(f"   Solde final: {start_balance + final_point:,.2f}â‚¬ ({final_point:+.2f}â‚¬)")
    
    # VÃ©rification de l'hypothÃ¨se -800â‚¬
    print(f"\nðŸŽ¯ RECHERCHE DES -800â‚¬")
    
    # Y a-t-il eu un moment oÃ¹ le compte Ã©tait Ã  19,200â‚¬ ?
    if start_balance + min_point <= 19200:
        print(f"   âœ… TROUVÃ‰! Ã€ {min_time}, le solde Ã©tait de {start_balance + min_point:,.2f}â‚¬")
        print(f"   Cela correspond Ã  une perte de {20000 - (start_balance + min_point):,.2f}â‚¬ depuis 20,000â‚¬")
    else:
        print(f"   âŒ Aucun moment trouvÃ© oÃ¹ le solde Ã©tait Ã  19,200â‚¬ ou moins")
    
    # Recherche de grosses pertes individuelles
    print(f"\nðŸ’¸ GROSSES PERTES INDIVIDUELLES (19-20 JUILLET)")
    big_losses = recent_trades[recent_trades['EUR_Flow'] < -200].sort_values('EUR_Flow')
    
    if len(big_losses) > 0:
        total_big_losses = big_losses['EUR_Flow'].sum()
        print(f"   {len(big_losses)} transactions avec perte >200â‚¬ = {total_big_losses:+.2f}â‚¬")
        
        for _, trade in big_losses.head(10).iterrows():
            print(f"      {trade['Date(UTC)']} {trade['Pair']}: {trade['EUR_Flow']:+.2f}â‚¬")
    
    # RÃ©sumÃ© final
    total_flow_2_days = recent_trades['EUR_Flow'].sum()
    print(f"\nðŸ“‹ RÃ‰SUMÃ‰ 19-20 JUILLET")
    print(f"   Flux total: {total_flow_2_days:+.2f}â‚¬")
    print(f"   Transactions: {len(recent_trades):,}")
    
    if abs(total_flow_2_days + 800) < 100:
        print(f"   ðŸŽ¯ POSSIBLE: Les -800â‚¬ correspondent aux trades de ces 2 jours")
    else:
        print(f"   â“ Les -800â‚¬ ne correspondent PAS aux trades de ces 2 jours")
    
    return recent_trades

if __name__ == "__main__":
    df = analyze_last_two_days('binance_export_20250720.csv')
